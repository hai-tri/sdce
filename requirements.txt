# Core dependencies
torch>=2.0.0
transformers>=4.35.0
datasets>=2.14.0
tokenizers>=0.14.0
hf_xet>=1.0.0

# Configuration
pyyaml>=6.0
omegaconf>=2.3.0

# Logging and monitoring
wandb>=0.15.0
tqdm>=4.65.0

# Numerical computing
numpy>=1.24.0

# Benchmarking (lm-evaluation-harness)
lm-eval>=0.4.0

# Flash Attention 2 (for CUDA/Ampere+ GPUs only)
# Uncomment if using CUDA with Ampere or newer GPU
# flash-attn>=2.3.0

# TPU Support (Google Cloud TPU)
# Uncomment if using TPU - install via:
# pip install torch_xla[tpu] -f https://storage.googleapis.com/libtpu-releases/index.html
# torch_xla>=2.0.0

# Optional: Accelerate for alternative distributed training
# accelerate>=0.24.0

# =============================================================================
# INSTALLATION GUIDE BY DEVICE/MODE
# =============================================================================
#
# SINGLE GPU (CUDA):
#   pip install -r requirements.txt
#   pip install flash-attn --no-build-isolation  # Optional, requires CUDA toolkit
#
# MULTI-GPU (torchrun/DDP):
#   pip install -r requirements.txt
#   pip install flash-attn --no-build-isolation  # Optional
#   # No additional packages needed - torch.distributed is built into PyTorch
#   # Launch with: torchrun --nproc_per_node=NUM_GPUS train.py --config config.yaml
#
# MPS (Apple Silicon):
#   pip install -r requirements.txt
#   # No additional packages needed - MPS support is built into PyTorch
#
# TPU (Google Cloud):
#   pip install -r requirements.txt
#   pip install torch_xla[tpu] -f https://storage.googleapis.com/libtpu-releases/index.html
#   # Set USE_TPU=1 environment variable or use --device tpu
#
# CPU:
#   pip install -r requirements.txt
#   # No additional packages needed
#
# =============================================================================
# DISTRIBUTED TRAINING QUICK REFERENCE
# =============================================================================
#
# Single node, 4 GPUs:
#   torchrun --nproc_per_node=4 train.py --config config.yaml
#
# Multi-node (2 nodes, 8 GPUs each):
#   # On node 0 (master):
#   torchrun --nproc_per_node=8 --nnodes=2 --node_rank=0 \
#       --master_addr=NODE0_IP --master_port=29500 \
#       train.py --config config.yaml
#
#   # On node 1:
#   torchrun --nproc_per_node=8 --nnodes=2 --node_rank=1 \
#       --master_addr=NODE0_IP --master_port=29500 \
#       train.py --config config.yaml
#
# SLURM cluster:
#   srun --ntasks-per-node=4 --gpus-per-task=1 \
#       torchrun --nproc_per_node=4 train.py --config config.yaml
#
# =============================================================================
